from rdkit import rdchem, Chem
import molli as ml
import pandas as pd
import numpy as np
from openbabel import openbabel
from math import sqrt


vdw_dict = {}
vdw_dict["C"] = 1.7
vdw_dict["H"] = 1.2
vdw_dict["O"] = 1.52
vdw_dict["N"] = 1.55
vdw_dict["F"] = 1.47
vdw_dict["S"] = 1.8
vdw_dict["P"] = 1.8
vdw_dict["Cl"] = 1.75
vdw_dict["CL"] = 1.75
vdw_dict["Si"] = 2.1
vdw_dict["SI"] = 2.1
vdw_dict["Br"] = 1.85
vdw_dict["BR"] = 1.85
vdw_dict["I"] = 1.95

symbols_for_rdf = ["C", "N", "S", "O", "F"]


def retrieve_bromide_rdf_descriptors(
    col, apd, increment: float = 1.5, radial_scale: int = 0
):
    """
    Takes collection and json-type atom property descriptors (generated by scraping function built for xTB outputs)

    outputs dataframe for each molecule with conformer-averaged descriptor columns and spherical slices for indices

    These are put into a dictionary with molecule names from the collection as keys.

    Shape of df is 20 rows (two 10 sphere slices for each half of the molecule) with 14 columns of electronic and indicator
    RDFs

    This should be applicable to nitrogen nucleophiles with the exception that one atom list with all atoms should be passed.
    This would give an output with 10 extra rows that could be trimmed or just removed later with variance threshold.

    """
    mol_rdfs = {}  # Going to store dfs in here with name for retrieval for now
    # conf_rdfs = {}
    # print(list(df[3]))
    for mol in col:
        # atom_props = apd[mol.name]
        # print(apd.keys())
        rdf_df = pd.DataFrame(index=["sphere_" + str(i) for i in range(10)])
        rdf_df.name = mol.name
        ### Get reference atoms
        labels = [f.symbol for f in mol.atoms]
        br_atom = mol.get_atoms_by_symbol(symbol="Br")[0]
        br_idx = mol.atoms.index(br_atom)
        conn = mol.get_connected_atoms(br_atom)
        if len(conn) != 1:
            raise Exception(
                "More than one group found bonded to Br atom. Check structures"
            )
        elif len(conn) == 1:
            ipso_atom = list(conn)[0]
        else:
            print("foundglitch")
        ipso_idx = mol.atoms.index(ipso_atom)
        rdk_mol = Chem.MolFromMol2Block(mol.to_mol2(), sanitize=False)
        if rdk_mol == None:
            # obabel_ = ml.OpenBabelDriver(name=mol.name,scratch_dir=os.getcwd(),nprocs=1)
            # out = obabel_.convert(mol_text=mol.to_mol2(),src="mol2",dest="smi")
            # print(out)
            obconv = openbabel.OBConversion()
            obconv.SetInAndOutFormats("mol2", "smi")
            obmol = openbabel.OBMol()
            with open("buffer.mol2", "w") as g:
                g.write(mol.to_mol2())
            obconv.ReadFile(obmol, "buffer.mol2")
            obconv.Convert()
            smi = obconv.WriteString(obmol).split()[0]
            if "([N](=O)[O-])" in smi:
                smi = smi.replace("([N](=O)[O-])", "([N+](=O)[O-])")
            # print(smi)
            rdk_mol = Chem.MolFromSmiles(smi)
            # print(rdk_mol)
            # break
        leftref = get_left_reference(rdk_mol, ipso_idx, br_idx)
        conf_rdfs = {}
        for k, conf in enumerate(mol.conformers):
            df = pd.DataFrame.from_dict(apd[mol.name][k], orient="columns")
            coords = conf.coord
            a, b, c, d = get_molplane(coords, br_idx, ipso_idx, leftref)
            e, f, g, h = get_orthogonal_plane(
                coords, br_idx, ipso_idx, a, b, c, leftref
            )
            h1, h2 = sort_into_halves(mol, conf, e, f, g, h)
            for prop in df.index:
                rdf_ser_1 = get_rdf(
                    coords,
                    br_idx,
                    h1,
                    df.loc[prop],
                    radial_scaling=radial_scale,
                    inc_size=increment,
                    first_int=1.80,
                )
                rdf_ser_2 = get_rdf(
                    coords,
                    br_idx,
                    h2,
                    df.loc[prop],
                    radial_scaling=radial_scale,
                    inc_size=increment,
                    first_int=1.80,
                )
                if prop in conf_rdfs.keys():
                    conf_rdfs[prop].append([list(rdf_ser_1), list(rdf_ser_2)])
                else:
                    conf_rdfs[prop] = [[list(rdf_ser_1), list(rdf_ser_2)]]
            rdf_ser_3 = get_atom_ind_rdf(
                mol.atoms, coords, br_idx, h1, inc_size=increment, first_int=1.80
            )
            rdf_ser_4 = get_atom_ind_rdf(
                mol.atoms, coords, br_idx, h2, inc_size=increment, first_int=1.80
            )
        for sym, _3, _4 in zip(symbols_for_rdf, rdf_ser_3, rdf_ser_4):
            conf_rdfs[sym + "_rdf"] = [[_3, _4]]
        desc_df = pd.DataFrame()
        for prop, values in conf_rdfs.items():
            array_ = np.array(values)
            avg_array = np.mean(array_, axis=0)
            desc_df[prop] = pd.concat([pd.Series(f) for f in avg_array], axis=0)
        desc_df.index = ["slice_" + str(f + 1) for f in range(20)]
        mol_rdfs[mol.name] = desc_df
    print("all done")
    return mol_rdfs


def get_amine_ref_n(mol: ml.Molecule):
    """
    Returns the reference atom index for the nitrogen with an H (assumes only one)
    """
    nit_atm = False
    for atm in mol.get_atoms_by_symbol(symbol="N"):
        nbrs = mol.get_connected_atoms(atm)
        for nbr in nbrs:
            # print(nbr.symbol)
            if nbr.symbol == "H":
                nit_atm = atm
                return nit_atm


def retrieve_amine_rdf_descriptors(
    col, apd, increment: float = 1.1, radial_scale: int = 0
):
    """
    Takes collection and json-type atom property descriptors (generated by scraping function built for xTB outputs)

    outputs dataframe for each molecule with conformer-averaged descriptor columns and spherical slices for indices

    These are put into a dictionary with molecule names from the collection as keys.

    Shape of df is 20 rows (two 10 sphere slices for each half of the molecule) with 14 columns of electronic and indicator
    RDFs

    This should be applicable to nitrogen nucleophiles with the exception that one atom list with all atoms should be passed.
    This would give an output with 10 extra rows that could be trimmed or just removed later with variance threshold.

    """
    mol_rdfs = {}  # Going to store dfs in here with name for retrieval for now
    # conf_rdfs = {}
    # print(list(df[3]))
    for mol in col:
        # atom_props = apd[mol.name]
        # print(apd.keys())
        rdf_df = pd.DataFrame(index=["sphere_" + str(i) for i in range(10)])
        rdf_df.name = mol.name
        ### Get reference atoms
        # labels = [f.symbol for f in mol.atoms]
        # br_atom = mol.get_atoms_by_symbol(symbol='Br')[0]
        n_atom = get_amine_ref_n(mol)
        n_idx = mol.atoms.index(n_atom)
        conn = mol.get_connected_atoms(n_atom)
        if len(conn) == 1:
            raise Exception(
                "More than one group found bonded to Br atom. Check structures"
            )
        # elif len(conn) == 3: ipso_atom =
        # else: print('foundglitch')
        # ipso_idx = mol.atoms.index(ipso_atom)
        # rdk_mol = Chem.MolFromMol2Block(mol.to_mol2(),sanitize=False)
        # if rdk_mol == None:
        #     # obabel_ = ml.OpenBabelDriver(name=mol.name,scratch_dir=os.getcwd(),nprocs=1)
        #     # out = obabel_.convert(mol_text=mol.to_mol2(),src="mol2",dest="smi")
        #     # print(out)
        #     obconv = openbabel.OBConversion()
        #     obconv.SetInAndOutFormats("mol2","smi")
        #     obmol = openbabel.OBMol()
        #     with open('buffer.mol2','w') as g:
        #         g.write(mol.to_mol2())
        #     obconv.ReadFile(obmol,'buffer.mol2')
        #     obconv.Convert()
        #     smi = obconv.WriteString(obmol).split()[0]
        #     if '([N](=O)[O-])' in smi:
        #         smi = smi.replace('([N](=O)[O-])','([N+](=O)[O-])')
        #     # print(smi)
        #     rdk_mol = Chem.MolFromSmiles(smi)
        #     # print(rdk_mol)
        #     # break
        # leftref = get_left_reference(rdk_mol,ipso_idx,n_idx)
        conf_rdfs = {}
        a_idx_l = [mol.atoms.index(f) for f in mol.atoms]
        for k, conf in enumerate(mol.conformers):
            df = pd.DataFrame.from_dict(apd[mol.name][k], orient="columns")
            coords = conf.coord
            # a,b,c,d = get_molplane(coords,n_idx,ipso_idx,leftref)
            # e,f,g,h = get_orthogonal_plane(coords,n_idx,ipso_idx,a,b,c,leftref)
            # h1,h2 = sort_into_halves(mol,conf,e,f,g,h)
            for prop in df.index:
                rdf_ser_1 = get_rdf(
                    coords,
                    n_idx,
                    a_idx_l,
                    df.loc[prop],
                    radial_scaling=radial_scale,
                    inc_size=increment,
                    first_int=1.20,
                )
                if prop in conf_rdfs.keys():
                    conf_rdfs[prop].append([list(rdf_ser_1)])
                else:
                    conf_rdfs[prop] = [[list(rdf_ser_1)]]
            rdf_ser_3 = get_atom_ind_rdf(
                mol.atoms, coords, n_idx, a_idx_l, inc_size=increment, first_int=1.20
            )
        for sym, _3 in zip(symbols_for_rdf, rdf_ser_3):
            conf_rdfs[sym + "_rdf"] = [[_3]]
        desc_df = pd.DataFrame()
        for prop, values in conf_rdfs.items():
            array_ = np.array(values)
            avg_array = np.mean(array_, axis=0)
            desc_df[prop] = pd.concat([pd.Series(f) for f in avg_array], axis=0)
        desc_df.index = ["slice_" + str(f + 1) for f in range(10)]
        mol_rdfs[mol.name] = desc_df
    print("all done")
    return mol_rdfs


def get_rdf(
    coords: ml.dtypes.CartesianGeometry,
    reference_idx: int,
    atom_list,
    all_atoms_property_list: list,
    inc_size=0.90,
    first_int: float = 1.80,
    radial_scaling: int or None = 0,
):

    """
    Takes coordinates for molecule, reference atom index, list of atom indices to compute for, and property list ordered by atom idx

    radial_scaling is an exponent for 1/(r^n) scaling the descriptors - whatever they may be

    """
    al = []
    bl = []
    cl = []
    dl = []
    el = []
    fl = []
    gl = []
    hl = []
    il = []
    jl = []
    central_atom = coords[reference_idx]
    # print(atom_list)
    for x in atom_list:
        point = coords[x]
        # print(point)
        # print(central_atom)
        dist = sqrt(
            (
                (float(central_atom[0]) - float(point[0])) ** 2
                + (float(central_atom[1]) - float(point[1])) ** 2
                + (float(central_atom[2]) - float(point[2])) ** 2
            )
        )
        # atom = ''.join([i for i in x if not i.isdigit()])
        property = list(all_atoms_property_list)[x]
        try:
            property_ = float(property)
        except:
            property_ = 4.1888 * vdw_dict[property] ** 3
        const = first_int
        if radial_scaling == 0 or radial_scaling == None:
            pass
        elif type(radial_scaling) is int and radial_scaling != 0:
            property_ = property_ / (dist**radial_scaling)
        else:
            raise ValueError("radial scaling exponent should be an integer or None")
        if dist <= const + inc_size:
            al.append(property_)
        elif dist > const + inc_size and dist <= const + inc_size * 2:
            bl.append(property_)
        elif dist > const + inc_size * 2 and dist <= const + inc_size * 3:
            cl.append(property_)
        elif dist > const + inc_size * 3 and dist <= const + inc_size * 4:
            dl.append(property_)
        elif dist > const + inc_size * 4 and dist <= const + inc_size * 5:
            el.append(property_)
        elif dist > const + inc_size * 5 and dist <= const + inc_size * 6:
            fl.append(property_)
        elif dist > const + inc_size * 6 and dist <= const + inc_size * 7:
            gl.append(property_)
        elif dist > const + inc_size * 7 and dist <= const + inc_size * 8:
            hl.append(property_)
        elif dist > const + inc_size * 8 and dist <= const + inc_size * 9:
            il.append(property_)
        elif dist > const + inc_size * 9:
            jl.append(property_)
    series_ = pd.Series(
        [
            sum(al),
            sum(bl),
            sum(cl),
            sum(dl),
            sum(el),
            sum(fl),
            sum(gl),
            sum(hl),
            sum(il),
            sum(jl),
        ],
        index=["sphere_" + str(f + 1) for f in range(10)],
    )
    """
    print al
    print bl
    print cl
    print dl
    print el
    print fl
    print gl
    print hl
    print il
    print jl
    """
    return series_


def get_atom_ind_rdf(
    atoms: list[ml.dtypes.Atom],
    coords: ml.dtypes.CartesianGeometry,
    reference_idx: int,
    atom_list,
    first_int: float = 1.80,
    inc_size=0.90,
):
    """
    Takes atoms and returns simple binary indicator for presence of specific atom types. These are not distance-weighted.
    """
    atomtypes = ["C", "N", "S", "O", "F"]
    outlist = []
    for symb in atomtypes:
        al = []
        bl = []
        cl = []
        dl = []
        el = []
        fl = []
        gl = []
        hl = []
        il = []
        jl = []
        central_atom = coords[reference_idx]
        # print(atom_list)
        for x in atom_list:
            point = coords[x]
            symbol = atoms[x].symbol
            if symbol != symb:
                continue
            dist = sqrt(
                (
                    (float(central_atom[0]) - float(point[0])) ** 2
                    + (float(central_atom[1]) - float(point[1])) ** 2
                    + (float(central_atom[2]) - float(point[2])) ** 2
                )
            )
            const = first_int
            if dist <= const + inc_size:
                al.append(1)
            elif dist > const + inc_size and dist <= const + inc_size * 2:
                bl.append(1)
            elif dist > const + inc_size * 2 and dist <= const + inc_size * 3:
                cl.append(1)
            elif dist > const + inc_size * 3 and dist <= const + inc_size * 4:
                dl.append(1)
            elif dist > const + inc_size * 4 and dist <= const + inc_size * 5:
                el.append(1)
            elif dist > const + inc_size * 5 and dist <= const + inc_size * 6:
                fl.append(1)
            elif dist > const + inc_size * 6 and dist <= const + inc_size * 7:
                gl.append(1)
            elif dist > const + inc_size * 7 and dist <= const + inc_size * 8:
                hl.append(1)
            elif dist > const + inc_size * 8 and dist <= const + inc_size * 9:
                il.append(1)
            elif dist > const + inc_size * 9:
                jl.append(1)
        series_ = [
            sum(al),
            sum(bl),
            sum(cl),
            sum(dl),
            sum(el),
            sum(fl),
            sum(gl),
            sum(hl),
            sum(il),
            sum(jl),
        ]
        outlist.append(series_)
    # output = np.array(outlist).T.tolist()
    output = outlist
    return output


def get_molplane(coords: np.array, ref_1, ref_2, ref_3):
    """
    Makes plane of molecule. Bromide for bromides, nitrogen for amines as ref atom. Mol is rdkit mol
    """
    p1 = np.array(coords[ref_1])
    p2 = np.array(coords[ref_2])
    p3 = np.array(coords[ref_3])
    # print(p1,p2,p3)
    v1 = p2 - p1
    v2 = p3 - p1
    cp = np.cross(v1, v2)
    # print(v1)
    # print(v2)
    # print(cp)
    a, b, c = cp
    d = np.dot(cp, p1)
    return a, b, c, d


def get_orthogonal_plane(coords: np.array, ref_1, ref_2, a, b, c, leftref):
    """
    Retrieve orthogonal plane to molecule, but containing reactive atom
    ref1 is the reactive atom (br or n)
    ref2 is the atom attached to it (for making a direction towards the molecule)
    """
    p1 = np.array(coords[ref_1])
    p2 = np.array(coords[ref_2])
    p4 = np.array(coords[leftref])  # for "positive" direction left/right
    v1 = p2 - p1
    v2 = np.array([a, b, c])
    cp = np.cross(v1, v2)
    e, f, g = cp
    vc = np.array([e, f, g])
    # print('norm vect',vc)
    # print('p1',p1)
    # print('p4',p4)
    # print(np.dot(vc,p4))
    # print(leftref)
    # print(ref1)
    if np.dot(vc, p4) > 0:
        h = np.dot(vc, p1)
        return e, f, g, h
    elif np.dot(vc, p4) < 0:
        cp = np.cross(v2, v1)
        e, f, g = cp
        vc = np.array([e, f, g])
        h = np.dot(vc, p1)
        return e, f, g, h
    else:
        print("Not finding direction")


def sort_into_halves(mol: ml.Molecule, conf: ml.dtypes.CartesianGeometry, e, f, g, h):
    """
    This function takes in the atom list and spits out a list of lists with atoms sorted
    into octants. This is done with the three orthonormal planes defined by get_orthogonal_planes
    """
    coords: np.array = conf.coord
    oct1 = []
    oct2 = []
    cp = np.array([e, f, g])
    # cp_ = [np.float64(e),np.float64(f),np.float64(g)]
    for i, pos in enumerate(coords):
        direction_ = (np.tensordot(pos, cp, axes=1) - h) / abs(
            sqrt(e**2 + f**2 + g**2)
        )
        if direction_ > 0.15:
            oct1.append(i)
        elif direction_ < -0.15:
            oct2.append(i)
    return [oct1, oct2]


def get_left_reference(mol: Chem.rdchem.Mol, ipso_idx, br_idx):
    """
    return leftref
    """
    ipso_reference = mol.GetAtomWithIdx(ipso_idx)
    br_ref = mol.GetAtomWithIdx(br_idx)
    ortho_het, meta_het = get_ortho_meta_symbols(mol, ipso_idx)
    # print(ortho_het,meta_het)
    if len(ortho_het) == 0:  # no ortho heteroatoms
        less_sub = get_less_substituted_ortho(mol, ipso_idx)
        # print(less_sub,'less_sub_ortho')
        if less_sub == None:  # ortho both the same
            if len(meta_het) == 0:  # no meta het, so using substitution
                less_meta_sub = get_less_substituted_meta(mol, ipso_idx)
                # print(less_meta_sub,'less_meta_sub')
                if less_meta_sub == None:
                    nbrs = [
                        f for f in ipso_reference.GetNeighbors() if f.GetIdx() != br_idx
                    ]
                    # print([f.GetIdx() for f in nbrs])
                    leftref = nbrs[0].GetIdx()  # arbitrary; symmetric
                elif (
                    less_meta_sub != None
                ):  # using less substituted meta atom for left reference
                    leftref = less_meta_sub
            elif len(meta_het) == 1:  # list of tuples (symbol, idx, atomic num)
                leftref = meta_het[0][1]
            elif len(meta_het) == 2:
                if (
                    meta_het[0][2] > meta_het[1][2]
                ):  # atomic number of first greater than atomic number of second
                    leftref = meta_het[0][1]
                elif meta_het[0][2] < meta_het[1][2]:
                    leftref = meta_het[1][1]
                elif meta_het[0][2] == meta_het[1][2]:
                    leftref = meta_het[0][1]  # arbitrary if they are the same
        elif less_sub != None:
            leftref = less_sub  # If one side is less substituted AND no heteroatoms were found
    elif len(ortho_het) == 1:
        leftref = ortho_het[0][1]  # heteroatom in ortho defines
    elif len(ortho_het) == 2:  # both ortho are het
        if (
            ortho_het[0][2] > ortho_het[1][2]
        ):  # atomic number of first greater than atomic number of second
            leftref = ortho_het[0][1]
        elif ortho_het[0][2] < ortho_het[1][2]:
            leftref = ortho_het[1][1]
        elif ortho_het[0][2] == ortho_het[1][2]:
            leftref = ortho_het[0][1]  # arbitrary if they are the same
    else:
        print("Error! Could not find bromide left reference after all conditions")
    return leftref


def get_ortho_meta_symbols(mol: Chem.rdchem.Mol, aryl_ref):
    """
    Finds out if and what heteroatoms are in the ortho-positions of aniline-type amines
    Returns list of ortho heteroatoms and then meta heteroatoms
    Form is: tuple (symbol,index,atomicnumber)
    Third value can be used to sort these by importance

    This should work for bromides!!!
    Uses ipso carbon as reference atom.
    """
    pt = Chem.GetPeriodicTable()
    # if is_aniline(mol,refn)==False:
    #     print('error! trying to use aniline func on non aniline!')
    #     return None
    ar_atm = get_aromatic_atoms(mol)  # all aryl atoms
    # print(ar_atm,aryl_ref)
    if aryl_ref not in ar_atm:
        print("weird")
        return None  # This is weird; error here if this happens
    het_ar_atm = []  # list of tuples describing heteroarene heteroatoms, empty if none
    for atm in ar_atm:  # Loop over aromatic atoms to find heteroaromatic atoms
        symb = mol.GetAtomWithIdx(atm).GetSymbol()
        if symb != "C":
            het_ar_atm.append(tuple([symb, atm]))
    refatom = mol.GetAtomWithIdx(aryl_ref)
    nbrs = refatom.GetNeighbors()
    ortho_het = []
    meta_het = []
    for nbr in nbrs:  # This looks at ortho atoms
        test_value = tuple([nbr.GetSymbol(), nbr.GetIdx()])
        if test_value in het_ar_atm:
            ortho_het.append(
                tuple([f for f in test_value] + [pt.GetAtomicNumber(test_value[0])])
            )
        nbr2 = [f for f in nbr.GetNeighbors() if f not in nbrs]
        for nbrr in nbr2:  # This looks at one further atom out from ortho
            test_val_2 = tuple([nbrr.GetSymbol(), nbrr.GetIdx()])
            if test_val_2 in het_ar_atm:
                meta_het.append(
                    tuple([f for f in test_val_2] + [pt.GetAtomicNumber(test_val_2[0])])
                )
    # print(ortho_het,meta_het)
    return ortho_het, meta_het


def get_aromatic_atoms(mol: Chem.rdchem.Mol):
    q = rdqueries.IsAromaticQueryAtom()
    return [x.GetIdx() for x in mol.GetAtomsMatchingQuery(q)]


def get_less_substituted_ortho(mol: Chem.rdchem.Mol, atomidx):
    atomref = mol.GetAtomWithIdx(atomidx)
    nbrs = atomref.GetNeighbors()
    nbrs_ = [
        f
        for f in nbrs
        if f.GetSymbol() != "H" and f.GetSymbol() != "Br" and f.GetSymbol() != "N"
    ]  # No H, Br, or N
    nbrlist = [[k.GetSymbol() for k in f.GetNeighbors()] for f in nbrs_]
    cntlist = [f.count("H") for f in nbrlist]
    if cntlist.count(cntlist[0]) == len(cntlist):
        return None  # This means H count is same
    min_v = min(cntlist)
    min_indx = cntlist.index(min_v)
    lesssub = nbrs_[min_indx].GetIdx()
    return lesssub


def get_less_substituted_meta(mol: Chem.rdchem.Mol, ipsoidx):
    atomref = mol.GetAtomWithIdx(ipsoidx)
    nbrs = atomref.GetNeighbors()
    nbrs_ = [f for f in nbrs if f.GetSymbol() != "H"]
    atomrings = mol.GetRingInfo().AtomRings()
    for ring in atomrings:
        if ipsoidx in ring:
            mainring = ring
    meta_ = [
        [
            k
            for k in f.GetNeighbors()
            if k.GetIdx() not in [p.GetIdx() for p in nbrs_]
            and k.GetSymbol != "H"
            and k.GetIdx() in mainring
            and k.GetIdx() != ipsoidx
        ]
        for f in nbrs_
    ]
    meta_ = [p for p in meta_ if len(p) != 0]
    # for f in meta_:
    #     print(f,'test')
    meta_type_list = [
        [k.GetSymbol() for k in f[0].GetNeighbors()] for f in meta_
    ]  # List with one item; need index in nested inner list
    cntlist = [f.count("H") for f in meta_type_list]
    if cntlist.count(cntlist[0]) == len(cntlist):
        return None  # This means H count is same
    min_v = min(cntlist)
    min_indx = cntlist.index(min_v)
    lesssub = meta_[min_indx][0].GetIdx()
    # print(lesssub)
    return lesssub


def trim_out_of_sample(partition: tuple, reacts: str):
    """
    Pass a string ##_## for amine_bromide that needs to be out of sample. This function will return the partitioned dataframes with those samples
    removed.
    """
    xtr, xval, xte, ytr, yval, yte = [pd.DataFrame(f[0], index=f[1]) for f in partition]
    to_move_tr = get_handles_by_reactants(reacts, ytr.index)
    to_move_va = get_handles_by_reactants(reacts, yval.index)
    # to_move_tot = to_move_tr+to_move_va
    x_trcut = xtr.loc[to_move_tr]
    y_trcut = ytr.loc[to_move_tr]
    xtr.drop(index=to_move_tr, inplace=True)
    ytr.drop(index=to_move_tr, inplace=True)
    x_vacut = xval.loc[to_move_va]
    y_vacut = yval.loc[to_move_va]
    xval.drop(index=to_move_va, inplace=True)
    yval.drop(index=to_move_va, inplace=True)
    xte = pd.concat((xte, x_trcut, x_vacut), axis=0)
    yte = pd.concat((yte, y_trcut, y_vacut), axis=0)
    return xtr, xval, xte, ytr, yval, yte


def get_handles_by_reactants(str_, handles_):
    out = []
    for k in handles_:
        # print(k.rsplit('_',3)[0])
        # print(str_)
        if k.rsplit("_", 3)[0] == str_:
            out.append(k)
    return out


def randomize_features(feat=np.array):
    """
    Accepts feature array and randomizes values

    """
    feat_ = feat
    rng = np.random.default_rng()
    feats = rng.random(out=feat)
    return feats


def make_randomized_features(
    am_dict, br_dict, catfile=None, solvfile=None, basefile=None
):
    """
    For running randomized feature control

    Pass dict of dataframes to this to randomize substrate features

    Handles are the dataset partitions (as a tuple...these will be returned with the desired order but randomized)

    output is AMINE, BROMIDE, CATALYST, SOLVENT, BASE
    """
    directory = "descriptors/"

    if basefile == None:
        basefile = directory + "base_params.csv"
    else:
        basefile = basefile
    basedf = pd.read_csv(basefile, header=None, index_col=0).transpose()
    if solvfile == None:
        solvfile = directory + "solvent_params.csv"
    else:
        solvfile == solvfile
    solvdf = pd.read_csv(solvfile, header=None, index_col=0).transpose()
    if catfile == None:
        catfile = directory + "cat_aso_aeif_combined_11_2021.csv"
    else:
        catfile == catfile
    catdf = pd.read_csv(catfile, header=None, index_col=0).transpose()
    cat_rand = randomize_features(catdf.to_numpy())
    catdfrand = pd.DataFrame(cat_rand, index=catdf.index, columns=catdf.columns)
    solv_rand = randomize_features(solvdf.to_numpy())
    solvdfrand = pd.DataFrame(solv_rand, index=solvdf.index, columns=solvdf.columns)
    base_rand = randomize_features(basedf.to_numpy())
    basedfrand = pd.DataFrame(base_rand, index=basedf.index, columns=basedf.columns)
    br_dict_rand = {}
    am_dict_rand = {}
    for k, v in am_dict.items():
        rand_f = randomize_features(np.array(v.iloc[:, :9].to_numpy()))
        rand_int = np.random.randint(0, 3, v.iloc[:, 9:].to_numpy().shape)
        concat = np.concatenate((rand_f, rand_int), axis=1)
        am_dict_rand[k] = pd.DataFrame(concat, index=v.index, columns=v.columns)
    for k, v in br_dict.items():
        rand_f = randomize_features(np.array(v.iloc[:, :9].to_numpy()))
        rand_int = np.random.randint(0, 3, v.iloc[:, 9:].to_numpy().shape)
        concat = np.concatenate((rand_f, rand_int), axis=1)
        br_dict_rand[k] = pd.DataFrame(concat, index=v.index, columns=v.columns)
    return am_dict_rand, br_dict_rand, catdfrand, solvdfrand, basedfrand


def assemble_random_descriptors_from_handles(handle_input, desc: tuple):
    """
    Assemble descriptors from output tuple of make_randomized_features function call

    To do this for all dataset compounds, pass every am_br joined with a comma

    """
    if type(handle_input) == str:
        rxn_hndls = [f for f in handle_input.split(",") if f != ""]
        prophetic = True
    elif type(handle_input) == list:
        rxn_hndls = [tuple(f.rsplit("_")) for f in handle_input]
        prophetic = False
    else:
        raise ValueError(
            "Must pass manual string input of handles OR list from dataset"
        )

    am_dict_rand, br_dict_rand, cat_rand, solv_rand, base_rand = desc
    basedf = base_rand
    solvdf = solv_rand
    catdf = cat_rand
    br_dict = br_dict_rand
    am_dict = am_dict_rand
    # print(catdf)

    ### Trying to assemble descriptors for labelled examples with specific conditions ###
    if prophetic == False:
        columns = []
        labels = []
        for i, handle in enumerate(rxn_hndls):
            am, br, cat, solv, base = handle
            catdesc = catdf[cat].tolist()
            solvdesc = solvdf[int(solv)].tolist()
            basedesc = basedf[base].tolist()
            amdesc = []
            for key, val in am_dict[am].iteritems():  # This is a pd df
                amdesc.extend(val.tolist())
            brdesc = []
            for key, val in br_dict[br].iteritems():
                brdesc.extend(val.tolist())
            handlestring = handle_input[i]
            columns.append(amdesc + brdesc + catdesc + solvdesc + basedesc)
            labels.append(handlestring)
        outdf = pd.DataFrame(columns, index=labels).transpose()
        # print(outdf)
        return outdf

    ### Trying to assemble descriptors for ALL conditions for specific amine/bromide couplings ###
    elif prophetic == True:
        solv_base_cond = ["1_a", "1_b", "1_c", "2_a", "2_b", "2_c", "3_a", "3_b", "3_c"]
        allcats = [str(f + 1) for f in range(21) if f != 14]
        s = "{}_{}_{}"
        exp_handles = []
        for combination in itertools.product(rxn_hndls, allcats, solv_base_cond):
            exp_handles.append(s.format(*combination))
        columns = []
        labels = []
        for handle in exp_handles:
            am, br, cat, solv, base = tuple(handle.split("_"))
            catdesc = catdf[cat].tolist()
            solvdesc = solvdf[int(solv)].tolist()
            basedesc = basedf[base].tolist()
            amdesc = []
            for key, val in am_dict[am].iteritems():  # This is a pd df
                amdesc.extend(val.tolist())
            brdesc = []
            for key, val in br_dict[br].iteritems():
                brdesc.extend(val.tolist())
            columns.append(amdesc + brdesc + catdesc + solvdesc + basedesc)
            labels.append(handle)
            # outdf[handle] = amdesc+brdesc+catdesc+solvdesc+basedesc
        outdf = pd.DataFrame(columns, index=labels).transpose()
        # print(outdf)
        return outdf


def outsamp_splits(
    data_df: pd.DataFrame,
    num_coup=5,
    save_mask=True,
    val_int=True,
    val_split=10,
    test_list=None,
):
    """
    Split dataset to withhold specific plates.

    Get split handles in tuple.

    Validation boolean decides if output is (train,validate,test)

    The num_coup integer indicates the number of am_br reactant combinations to withhold into the
    validate or test split (each)

    Val split ignored unless val_int is True

    test_list overrides num_coup, and sets those couplings as the out of sample ones
    note: only works with internal validation

    """
    # no_exp = len(data_df.index)
    # rand_arr = np.random.randint(1,high=fold+1,size=no_exp,dtype=int)
    # if validation == False:
    #     train_mask = (rand_arr > 1).tolist()
    #     test_mask = (rand_arr == 1).tolist()
    #     mask_list = [train_mask,test_mask]
    # elif validation == True:
    #     train_mask = (rand_arr > 2).tolist()
    #     validate_mask = (rand_arr == 2).tolist()
    #     test_mask = (rand_arr == 1).tolist()
    #     mask_list = [train_mask,validate_mask,test_mask]
    # out = tuple([data_df.iloc[msk,:] for msk in mask_list])
    # return out
    if val_int == False:
        handles = data_df.index
        reacts = [f.rsplit("_", 3)[0] for f in handles]
        set_ = sorted(list(set(reacts)))
        if test_list == None:
            test = random.sample(set_, num_coup)
        elif type(test_list) == list:
            test = test_list
        temp = [f for f in set_ if f not in test]  # temp is train and val
        val = random.sample(temp, num_coup)  # val is sampling of temp (train + val)
        train = [f for f in temp if f not in val]  # train is temp if not in val
        tr_h = [f for f in handles if f.rsplit("_", 3)[0] in train]
        va_h = [f for f in handles if f.rsplit("_", 3)[0] in val]
        te_h = [f for f in handles if f.rsplit("_", 3)[0] in test]
        mask_list = [tr_h, va_h, te_h]
        if save_mask == False:
            out = tuple([data_df.loc[msk, :] for msk in mask_list])
            return out
        if save_mask == True:
            out = tuple([data_df.loc[msk, :] for msk in mask_list] + [val, test])
            return out
    elif (
        val_int == True
    ):  ##This is to keep test plates out of sample, BUT validation and train data from shared plates. This may be necessary on account of the stochasticity of modeling
        handles = data_df.index
        reacts = [f.rsplit("_", 3)[0] for f in handles]
        set_ = sorted(list(set(reacts)))
        if (
            test_list == None
        ):  # This is for randomly sampling a number of couplings ONLY IF TEST_LIST NOT SPECIFIED
            test = random.sample(set_, num_coup)
        elif (
            type(test_list) == list
        ):  # If test_list is specified, then this overrides everything else
            test = test_list
        te_h = [f for f in handles if f.rsplit("_", 3)[0] in test]
        temp = [
            f for f in handles if f.rsplit("_", 3)[0] not in test
        ]  # both train and val will come from here; handles, not am_br
        # print(np.rint(len(temp)/val_split))
        va_h = random.sample(
            temp, int(np.rint(len(temp) / val_split))
        )  # handles sampled randomly from train&val list of handles (temp)
        tr_h = [f for f in temp if f not in va_h]
        print(
            "check :", [f for f in tr_h if f in va_h or f in te_h]
        )  # data leakage test
        mask_list = [tr_h, va_h, te_h]
        if save_mask == False:
            out = tuple([data_df.loc[msk, :] for msk in mask_list])
            return out
        if save_mask == True:
            out = tuple([data_df.loc[msk, :] for msk in mask_list] + [test])
            return out


def outsamp_by_handle(data_df: pd.DataFrame, test_list=[]):
    """
    No validation; just gives train/test using passed handles for test examples.

    """
    handles = data_df.index
    train_list = [f for f in handles if f not in test_list]
    test = data_df.loc[test_list, :]
    train = data_df.loc[train_list, :]
    return train, test


def split_handles_reactants(reacts=[], handle_position: int = 1, handles=[]):
    """
    Partition dataset to withhold specific REACTANTS; flexible to any
    specified position in reaction handle (amine, bromide, catalyst, etc) NOTE: ONE-INDEXED
    """
    str_reacts = [str(f) for f in reacts]
    out_hand = [
        f for f in handles if f.strip().split("_")[handle_position - 1] in str_reacts
    ]  # clean up whitespace, split handles, check specific position for match
    return out_hand


def split_outsamp_reacts(
    dataset_: pd.DataFrame, amines=[], bromides=[], separate=False
):
    """
    Use this to split out of sample reactants in dataset partitions.

    This runs split_out_reactants

    Data should be row = instance

    "separate" boolean triggers optional output with specific handles for out of sample amines OR bromides
    """
    amine_out_hand = split_handles_reactants(
        reacts=amines, handle_position=1, handles=dataset_.index
    )
    # print(amine_out_hand)
    bromide_out_hand = split_handles_reactants(
        reacts=bromides, handle_position=2, handles=dataset_.index
    )
    # print(bromide_out_hand)
    outsamp_handles = sorted(
        list(set(amine_out_hand + bromide_out_hand))
    )  # remove duplicates (from any matches to both reactants) and provide consistent ordering
    if separate == False:
        return outsamp_handles
    elif separate == True:
        am_f = []
        br_f = []
        comb = [
            str(f[0]) + "_" + str(f[1]) for f in itertools.product(amines, bromides)
        ]
        # print(comb)
        both = [f for f in outsamp_handles if f.strip().rsplit("_", 3)[0] in comb]
        not_both = [f for f in outsamp_handles if f not in both]
        for k in amines:
            temp1 = split_handles_reactants(
                reacts=[str(k)], handle_position=1, handles=not_both
            )
            am_f.append(temp1)
        for m in bromides:
            temp2 = split_handles_reactants(
                reacts=[str(m)], handle_position=2, handles=not_both
            )
            br_f.append(temp2)
        return am_f, br_f, both, outsamp_handles
